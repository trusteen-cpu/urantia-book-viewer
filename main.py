import streamlit as st
import pandas as pd
import re
import os

# --- íŒŒì¼ ê²½ë¡œ ---
KO_PATH = os.path.join("data", "urantia_ko.txt")
EN_PATH = os.path.join("data", "urantia_en.txt")
GLOSSARY_PATH = os.path.join("data", "glossary.xlsx")

# --- ë°ì´í„° ë¡œë“œ ---
@st.cache_data
def load_texts():
    def parse_file(path):
        data = {}
        import chardet

        try:
            with open(path, "rb") as fb:
                raw = fb.read()
                enc = chardet.detect(raw)["encoding"]
                text = raw.decode(enc, errors="replace").splitlines()
            for line in text:
                line = line.strip()
                match = re.match(r"(\d+:\d+\.\d+)\s+(.*)", line)
                if match:
                    key = match.group(1).strip()
                    data[key] = match.group(2).strip()
        except Exception as e:
            st.error(f"âŒ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {path} â€” {e}")
        return data or {}

    ko_data = parse_file(KO_PATH)
    en_data = parse_file(EN_PATH)
    return ko_data, en_data


@st.cache_data
def load_glossary():
    df = pd.read_excel(GLOSSARY_PATH)
    df.columns = df.columns.str.lower()
    return df

ko_texts, en_texts = load_texts()
glossary = load_glossary()

# --- ê¸°ë³¸ UI ---
st.set_page_config(layout="wide")
st.title("ğŸ“˜ Urantia Book Viewer â€“ í¸/ì¥ ë‹¨ìœ„ ë³‘ë ¬ ë³´ê¸°")
st.caption("í•œê¸€ê³¼ ì˜ì–´ ì ˆë³„ ë³‘ë ¬ ì •ë ¬ + ìŠ¤í¬ë¡¤ ë™ê¸°í™”")

input_ref = st.text_input("Enter reference (ì˜ˆ: 111:7 or 196)", "")

# --- ê²€ìƒ‰ í•¨ìˆ˜ ---
def get_texts(prefix):
    """í¸(ì˜ˆ 196) ë˜ëŠ” ì¥(ì˜ˆ 111:7)ì„ ì¸ì‹í•´ ì „ì²´ êµ¬ì ˆì„ ë°˜í™˜"""
    if ":" in prefix:
        ko_matches = {k: v for k, v in ko_texts.items() if k.startswith(prefix + ".")}
        en_matches = {k: v for k, v in en_texts.items() if k.startswith(prefix + ".")}
    else:
        ko_matches = {k: v for k, v in ko_texts.items() if k.startswith(prefix + ":")}
        en_matches = {k: v for k, v in en_texts.items() if k.startswith(prefix + ":")}
    return ko_matches, en_matches

# --- CSS (ë™ê¸° ìŠ¤í¬ë¡¤ í¬í•¨) ---
st.markdown("""
<style>
.container {
  display: flex;
  gap: 8px;
  width: 100%;
  overflow: hidden;
}
.text-column {
  width: 50%;
  height: 70vh;
  overflow-y: scroll;
  padding: 10px;
  border: 1px solid #ccc;
  border-radius: 8px;
  background: #fafafa;
}
.verse {
  margin-bottom: 12px;
  line-height: 1.5;
}
.verse-num {
  font-weight: bold;
  color: #444;
}
</style>

<script>
const syncScroll = () => {
  const left = window.parent.document.querySelectorAll('.text-column')[0];
  const right = window.parent.document.querySelectorAll('.text-column')[1];
  if (left && right) {
    left.addEventListener('scroll', () => { right.scrollTop = left.scrollTop; });
    right.addEventListener('scroll', () => { left.scrollTop = right.scrollTop; });
  }
};
window.addEventListener('load', syncScroll);
</script>
""", unsafe_allow_html=True)

# --- ë³¸ë¬¸ ë Œë”ë§ ---
if input_ref:
    ko_matches, en_matches = get_texts(input_ref)
    if ko_matches:
        st.markdown(f"### ğŸ“– {input_ref} ì „ì²´ ë³´ê¸°")

        left_col, right_col = st.columns(2)
        with left_col:
            st.markdown("#### ğŸ‡°ğŸ‡· Korean Translation")
            st.markdown('<div class="text-column">', unsafe_allow_html=True)
            for key in sorted(ko_matches.keys(), key=lambda x: list(map(float, re.findall(r'\\d+', x)))):
                st.markdown(f'<div class="verse"><span class="verse-num">{key}</span> {ko_matches[key]}</div>', unsafe_allow_html=True)
            st.markdown("</div>", unsafe_allow_html=True)

        with right_col:
            st.markdown("#### ğŸ‡ºğŸ‡¸ English Original")
            st.markdown('<div class="text-column">', unsafe_allow_html=True)
            for key in sorted(en_matches.keys(), key=lambda x: list(map(float, re.findall(r'\\d+', x)))):
                st.markdown(f'<div class="verse"><span class="verse-num">{key}</span> {en_matches[key]}</div>', unsafe_allow_html=True)
            st.markdown("</div>", unsafe_allow_html=True)
    else:
        st.warning("âš ï¸ í•´ë‹¹ í¸ ë˜ëŠ” ì¥ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì˜ˆ: 111:7 ë˜ëŠ” 196 í˜•íƒœë¡œ ì…ë ¥í•˜ì„¸ìš”.")

# --- ìš©ì–´ì§‘ ---
st.divider()
st.subheader("ğŸ“š ìš©ì–´ì§‘ ê²€ìƒ‰")
search_term = st.text_input("ìš©ì–´ë‚˜ ë‹¨ì–´ ê²€ìƒ‰ (í•œê¸€ ë˜ëŠ” ì˜ì–´):", "")
if search_term:
    results = glossary[
        glossary["term-ko"].str.contains(search_term, case=False, na=False) |
        glossary["term-en"].str.contains(search_term, case=False, na=False)
    ]
    if not results.empty:
        st.write("### ğŸ” Glossary Results")
        for _, row in results.iterrows():
            st.markdown(f"**{row['term-ko']}** / *{row['term-en']}* â€” {row['description']}")
    else:
        st.info("No matching term found in glossary.")

