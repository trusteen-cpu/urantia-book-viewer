import streamlit as st
import pandas as pd
import re
import os

# ------------------------------------------------------------
# í˜ì´ì§€ ì„¤ì •
# ------------------------------------------------------------
st.set_page_config(page_title="Urantia Book Viewer", layout="wide")

# ------------------------------------------------------------
# íŒŒì¼ ê²½ë¡œ
# ------------------------------------------------------------
KO_PATH = os.path.join("data", "urantia_ko.txt")
EN_PATH = os.path.join("data", "urantia_en.txt")
GLOSSARY_PATH = os.path.join("data", "glossary.xlsx")

# ------------------------------------------------------------
# ì•ˆì „í•œ íŒŒì¼ ì½ê¸°
# ------------------------------------------------------------
def safe_read_lines(path):
    encodings = ["utf-8", "utf-8-sig", "cp949", "euc-kr", "utf-16", "latin-1"]
    for enc in encodings:
        try:
            with open(path, "r", encoding=enc) as f:
                return f.readlines()
        except Exception:
            continue
    with open(path, "r", encoding="utf-8", errors="replace") as f:
        return f.readlines()

def clean_text(t: str) -> str:
    return t.replace("\ufeff", "").replace("ï¿½", "").strip()

@st.cache_data
def load_texts():
    def parse_file(path):
        data = {}
        lines = safe_read_lines(path)
        for line in lines:
            line = line.strip()
            m = re.match(r"^(\d+:\d+\.\d+)\s+(.*)$", line)
            if m:
                data[m.group(1)] = clean_text(m.group(2))
        return data

    ko = parse_file(KO_PATH)
    en = parse_file(EN_PATH)
    return ko, en

@st.cache_data
def load_glossary():
    try:
        df = pd.read_excel(GLOSSARY_PATH)
        df.columns = df.columns.str.lower()
        return df
    except Exception:
        return pd.DataFrame(columns=["term-ko", "term-en", "description"])

ko_texts, en_texts = load_texts()
glossary = load_glossary()

# ------------------------------------------------------------
# ì°¸ì¡° ê²€ìƒ‰
# ------------------------------------------------------------
def get_pairs_by_ref(ref: str):
    pairs = []
    if re.match(r"^\d+:\d+\.\d+$", ref):
        if ref in ko_texts:
            pairs.append((ref, ko_texts[ref], en_texts.get(ref, "")))
        return pairs
    if re.match(r"^\d+:\d+$", ref):
        prefix = ref + "."
        for k in ko_texts:
            if k.startswith(prefix):
                pairs.append((k, ko_texts[k], en_texts.get(k, "")))
        return pairs
    if re.match(r"^\d+$", ref):
        prefix = ref + ":"
        for k in ko_texts:
            if k.startswith(prefix):
                pairs.append((k, ko_texts[k], en_texts.get(k, "")))
        return pairs
    return pairs

# ------------------------------------------------------------
# UI
# ------------------------------------------------------------
st.title("ğŸ“˜ Urantia Book Viewer")
st.caption("ì™¼ìª½ í•œê¸€ / ì˜¤ë¥¸ìª½ ì˜ì–´ ë³‘ë ¬ ë³´ê¸° (HTML ë Œë”ë§ ëª¨ë“œ)")

ref = st.text_input("ì°¸ì¡° ì…ë ¥ (ì˜ˆ: 196, 196:2, 196:2.3)", "").strip()

if ref:
    pairs = get_pairs_by_ref(ref)
    if not pairs:
        st.warning("ì¼ì¹˜í•˜ëŠ” ë³¸ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        html = """
        <html>
        <head>
        <style>
        body {
            font-family: 'Noto Sans KR', sans-serif;
            margin: 0;
            padding: 20px;
            background: #f7f7f7;
        }
        .pair {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 20px;
            margin-bottom: 15px;
        }
        .box {
            background: #ffffff;
            padding: 18px 20px;
            border-radius: 10px;
            box-shadow: 0 0 6px rgba(0,0,0,0.05);
            line-height: 1.9;
            font-size: 17px;
        }
        .box b { color: #003366; }
        </style>
        </head>
        <body>
        """

        for k, ko, en in pairs:
            html += f"""
            <div class='pair'>
                <div class='box'><b>{k}</b><br>{ko}</div>
                <div class='box'><b>{k}</b><br>{en}</div>
            </div>
            """

        html += "</body></html>"

        st.components.v1.html(html, height=6000, scrolling=True)

else:
    st.info("ì˜ˆ: 196, 196:2, 196:2.3 í˜•íƒœë¡œ ê²€ìƒ‰í•´ ë³´ì„¸ìš”.")

# ------------------------------------------------------------
# ìš©ì–´ ê²€ìƒ‰
# ------------------------------------------------------------
st.markdown("---")
st.subheader("ğŸ” ìš©ì–´ ê²€ìƒ‰ (Glossary Search)")

term = st.text_input("ì°¾ê³  ì‹¶ì€ ìš©ì–´ (ì˜ì–´ ë˜ëŠ” í•œêµ­ì–´):", "", key="glossary_input")

if term:
    results = glossary[
        glossary["term-ko"].str.contains(term, case=False, na=False)
        | glossary["term-en"].str.contains(term, case=False, na=False)
    ]
    if not results.empty:
        for _, row in results.iterrows():
            st.markdown(f"""
            <div style='background:#eef2ff;padding:10px 14px;margin:10px 0;border-radius:8px;'>
            <b>{row['term-ko']}</b> / *{row['term-en']}*  
            â€” {row['description']}
            </div>
            """, unsafe_allow_html=True)
    else:
        st.info("ì¼ì¹˜í•˜ëŠ” ìš©ì–´ê°€ ì—†ìŠµë‹ˆë‹¤.")
else:
    st.caption("ì˜ˆ: â€˜ì‹ ë¹„ ëª¨ë‹ˆí„°â€™, â€˜Thought Adjusterâ€™, â€˜Nebadonâ€™ ë“±ì„ ì…ë ¥í•´ ë³´ì„¸ìš”.")

