import streamlit as st
import pandas as pd
import re
import os

# ------------------------------------------------------------
# í˜ì´ì§€ ì„¤ì •
# ------------------------------------------------------------
st.set_page_config(page_title="Urantia Book Viewer", layout="wide")

# ------------------------------------------------------------
# íŒŒì¼ ê²½ë¡œ
# ------------------------------------------------------------
KO_PATH = os.path.join("data", "urantia_ko.txt")
EN_PATH = os.path.join("data", "urantia_en.txt")
GLOSSARY_PATH = os.path.join("data", "glossary.xlsx")

# ------------------------------------------------------------
# ì•ˆì „í•œ íŒŒì¼ ì½ê¸°
# ------------------------------------------------------------
def safe_read_lines(path):
    encodings = ["utf-8", "utf-8-sig", "cp949", "euc-kr", "utf-16", "latin-1"]
    for enc in encodings:
        try:
            with open(path, "r", encoding=enc) as f:
                return f.readlines()
        except Exception:
            continue
    with open(path, "r", encoding="utf-8", errors="replace") as f:
        return f.readlines()

def clean_text(t: str) -> str:
    return t.replace("\ufeff", "").replace("ï¿½", "").strip()

@st.cache_data
def load_texts():
    def parse_file(path):
        data = {}
        lines = safe_read_lines(path)
        for line in lines:
            line = line.strip()
            m = re.match(r"^(\d+:\d+\.\d+)\s+(.*)$", line)
            if m:
                data[m.group(1)] = clean_text(m.group(2))
        return data

    ko = parse_file(KO_PATH)
    en = parse_file(EN_PATH)
    return ko, en

@st.cache_data
def load_glossary():
    try:
        df = pd.read_excel(GLOSSARY_PATH)
        df.columns = df.columns.str.lower()
        return df
    except Exception:
        return pd.DataFrame(columns=["term-ko", "term-en", "description"])

ko_texts, en_texts = load_texts()
glossary = load_glossary()

# ------------------------------------------------------------
# ì°¸ì¡° / ê²€ìƒ‰ ê³µìš© í•¨ìˆ˜
# ------------------------------------------------------------
def get_pairs_by_ref(ref: str):
    pairs = []
    if re.match(r"^\d+:\d+\.\d+$", ref):  # ì ˆ
        if ref in ko_texts:
            pairs.append((ref, ko_texts[ref], en_texts.get(ref, "")))
        return pairs
    if re.match(r"^\d+:\d+$", ref):  # ì¥
        prefix = ref + "."
        for k in ko_texts:
            if k.startswith(prefix):
                pairs.append((k, ko_texts[k], en_texts.get(k, "")))
        return pairs
    if re.match(r"^\d+$", ref):  # í¸
        prefix = ref + ":"
        for k in ko_texts:
            if k.startswith(prefix):
                pairs.append((k, ko_texts[k], en_texts.get(k, "")))
        return pairs
    return pairs

def make_parallel_html(pairs):
    html = """
    <html><head><meta charset='utf-8'>
    <style>
    body { font-family: 'Noto Sans KR', sans-serif; margin: 0; padding: 20px; background: #f7f7f7; }
    .pair { display: grid; grid-template-columns: 1fr 1fr; gap: 20px; margin-bottom: 14px; }
    .box { background: #fff; padding: 16px 20px; border-radius: 10px;
           box-shadow: 0 0 6px rgba(0,0,0,0.05); line-height: 1.9; font-size: 17px; }
    .box b { color: #003366; }
    </style></head><body>
    """
    for k, ko, en in pairs:
        html += f"""
        <div class='pair'>
            <div class='box'><b>{k}</b><br>{ko}</div>
            <div class='box'><b>{k}</b><br>{en}</div>
        </div>
        """
    html += "</body></html>"
    return html

# ------------------------------------------------------------
# UI
# ------------------------------------------------------------
st.title("ğŸ“˜ Urantia Book Viewer")
st.caption("ì™¼ìª½ í•œê¸€ / ì˜¤ë¥¸ìª½ ì˜ì–´ ë³‘ë ¬ ë³´ê¸° + ë³¸ë¬¸ ë‹¨ì–´ ê²€ìƒ‰ + ìš©ì–´ ê²€ìƒ‰")

# --- ì°¸ì¡° ì…ë ¥ ---
ref = st.text_input("ì°¸ì¡° ì…ë ¥ (ì˜ˆ: 196, 196:2, 196:2.3)", "", key="ref_input").strip()

# --- ë³¸ë¬¸ ê²€ìƒ‰ ---
keyword = st.text_input("ë³¸ë¬¸ ë‹¨ì–´ ê²€ìƒ‰ (ì˜ˆ: ì¡°ì ˆì, Adjuster ë“±)", "", key="keyword_search").strip()

# ------------------------------------------------------------
# ì°¸ì¡° ê²€ìƒ‰ ê²°ê³¼
# ------------------------------------------------------------
if ref:
    pairs = get_pairs_by_ref(ref)
    if pairs:
        html = make_parallel_html(pairs)
        st.components.v1.html(html, height=6000, scrolling=True)
    else:
        st.warning("ì¼ì¹˜í•˜ëŠ” ë³¸ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤. ì˜ˆ: 196, 196:2, 196:2.3")

# ------------------------------------------------------------
# ë‹¨ì–´ ê²€ìƒ‰ ê²°ê³¼
# ------------------------------------------------------------
elif keyword:
    matches = []
    for ref_, text in ko_texts.items():
        if keyword in text:
            matches.append((ref_, text, en_texts.get(ref_, "")))
    for ref_, text in en_texts.items():
        if keyword.lower() in text.lower() and ref_ not in [m[0] for m in matches]:
            matches.append((ref_, ko_texts.get(ref_, ""), text))

    if matches:
        st.markdown(f"**ğŸ” '{keyword}' ê²€ìƒ‰ ê²°ê³¼ â€” {len(matches)}ê°œ ì ˆ**")
        html = make_parallel_html(matches[:100])
        st.components.v1.html(html, height=6000, scrolling=True)
    else:
        st.info(f"'{keyword}' ê°€ í¬í•¨ëœ ë³¸ë¬¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# ------------------------------------------------------------
# ìš©ì–´ ê²€ìƒ‰
# ------------------------------------------------------------
st.markdown("---")
st.subheader("ğŸ“š ìš©ì–´ ê²€ìƒ‰ (Glossary Search)")
term = st.text_input("ì°¾ê³  ì‹¶ì€ ìš©ì–´ (ì˜ì–´ ë˜ëŠ” í•œêµ­ì–´):", "", key="glossary_input")

if term:
    results = glossary[
        glossary["term-ko"].str.contains(term, case=False, na=False)
        | glossary["term-en"].str.contains(term, case=False, na=False)
    ]
    if not results.empty:
        html = """
        <html><head><meta charset='utf-8'><style>
        body { font-family: 'Noto Sans KR', sans-serif; background:#f7f7f7; margin:0; padding:20px; }
        .term { background:#eef2ff; padding:12px 16px; border-radius:8px; margin-bottom:10px;
                line-height:1.7; font-size:16px; }
        </style></head><body>
        """
        for _, row in results.iterrows():
            html += f"<div class='term'><b>{row['term-ko']}</b> / *{row['term-en']}* â€” {row['description']}</div>"
        html += "</body></html>"
        st.components.v1.html(html, height=2000, scrolling=True)
    else:
        st.info("ì¼ì¹˜í•˜ëŠ” ìš©ì–´ê°€ ì—†ìŠµë‹ˆë‹¤.")
else:
    st.caption("ì˜ˆ: â€˜ì‹ ë¹„ ëª¨ë‹ˆí„°â€™, â€˜Thought Adjusterâ€™, â€˜Nebadonâ€™ ë“±ì„ ì…ë ¥í•´ ë³´ì„¸ìš”.")



